{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "819422fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# --- Paths for CTU-13 dataset ---\n",
    "dataset_files = {\n",
    "    '1': 'scenario_dataset_1/dataset_result.binetflow',\n",
    "    '2': 'scenario_dataset_2/dataset_result.binetflow',\n",
    "    '5': 'scenario_dataset_5/dataset_result.binetflow',\n",
    "    '9': 'scenario_dataset_9/dataset_result.binetflow',\n",
    "    '13': 'scenario_dataset_13/dataset_result.binetflow'\n",
    "}\n",
    "# --- End paths ---\n",
    "\n",
    "# Define the folder name to save sample results\n",
    "output_folder = 'sampled_data'\n",
    "\n",
    "# Create an empty dictionary to hold all COMPLETE DataFrames\n",
    "# This variable will persist after this cell is executed\n",
    "dict_of_dataframes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca5fe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai proses: Membaca data & mengambil sampel...\n",
      "Folder output 'sampled_data' telah disiapkan.\n",
      "\n",
      "--- Memproses Dataset 1 ---\n",
      "Membaca file: scenario_dataset_1/dataset_result.binetflow...\n",
      "Dataset 1 (100 baris) telah dimuat ke memori.\n",
      "Mengambil 100 baris acak dari file 1...\n",
      "Sukses! Sampel disimpan ke 'sampled_data\\scenario_dataset_1\\dataset_result.binetflow'\n",
      "\n",
      "--- Memproses Dataset 2 ---\n",
      "Membaca file: scenario_dataset_2/dataset_result.binetflow...\n",
      "Dataset 2 (100 baris) telah dimuat ke memori.\n",
      "Mengambil 100 baris acak dari file 2...\n",
      "Sukses! Sampel disimpan ke 'sampled_data\\scenario_dataset_2\\dataset_result.binetflow'\n",
      "\n",
      "--- Memproses Dataset 5 ---\n",
      "Membaca file: scenario_dataset_5/dataset_result.binetflow...\n",
      "Dataset 5 (100 baris) telah dimuat ke memori.\n",
      "Mengambil 100 baris acak dari file 5...\n",
      "Sukses! Sampel disimpan ke 'sampled_data\\scenario_dataset_5\\dataset_result.binetflow'\n",
      "\n",
      "--- Memproses Dataset 9 ---\n",
      "Membaca file: scenario_dataset_9/dataset_result.binetflow...\n",
      "Dataset 9 (100 baris) telah dimuat ke memori.\n",
      "Mengambil 100 baris acak dari file 9...\n",
      "Sukses! Sampel disimpan ke 'sampled_data\\scenario_dataset_9\\dataset_result.binetflow'\n",
      "\n",
      "--- Memproses Dataset 13 ---\n",
      "Membaca file: scenario_dataset_13/dataset_result.binetflow...\n",
      "Dataset 13 (100 baris) telah dimuat ke memori.\n",
      "Mengambil 100 baris acak dari file 13...\n",
      "Sukses! Sampel disimpan ke 'sampled_data\\scenario_dataset_13\\dataset_result.binetflow'\n",
      "\n",
      "--- Semua proses selesai ---\n",
      "Berhasil memuat 5 dataset ke memori.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting process: Reading data & taking samples...\")\n",
    "\n",
    "# 1. Create output folder if it doesn't exist\n",
    "try:\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    print(f\"Output folder '{output_folder}' has been prepared.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create folder '{output_folder}': {e}\")\n",
    "\n",
    "\n",
    "# 2. Loop, read, save to dict, take samples, and save samples\n",
    "for key, filepath in dataset_files.items():\n",
    "    try:\n",
    "        print(f\"\\n--- Processing Dataset {key} ---\")\n",
    "        print(f\"Reading file: {filepath}...\")\n",
    "        \n",
    "        # a. Read file\n",
    "        df = pd.read_csv(filepath, low_memory=False)\n",
    "        total_rows = len(df)\n",
    "        \n",
    "        # b. Save COMPLETE DataFrame to dictionary\n",
    "        # This fulfills your request to access it later\n",
    "        dict_of_dataframes[key] = df\n",
    "        print(f\"Dataset {key} ({total_rows} rows) has been loaded into memory.\")\n",
    "\n",
    "        # c. Determine sample size\n",
    "        sample_size = min(100, total_rows)\n",
    "        if sample_size < 100:\n",
    "            print(f\"Warning: File {key} only has {total_rows} rows. Taking {sample_size} rows.\")\n",
    "        else:\n",
    "            print(f\"Taking 100 random rows from file {key}...\")\n",
    "\n",
    "        # d. Take samples from the DataFrame that was just read\n",
    "        sampled_df_botnet_not_spam = df[\n",
    "            df['Label'].str.contains('botnet', case=False, na=False) &\n",
    "            ~df['Label'].str.contains('spam', case=False, na=False)\n",
    "        ].sample(n=3, random_state=42)\n",
    "\n",
    "        sampled_df_botnet_and_spam = df[\n",
    "            df['Label'].str.contains('botnet', case=False, na=False) &\n",
    "            df['Label'].str.contains('spam', case=False, na=False)\n",
    "        ].sample(n=3, random_state=42)\n",
    "\n",
    "        sampled_df_no_botnet_no_spam = df[\n",
    "            ~df['Label'].str.contains('botnet', case=False, na=False) &\n",
    "            ~df['Label'].str.contains('spam', case=False, na=False)\n",
    "        ].sample(n=4, random_state=42)\n",
    "\n",
    "        # Combine the three DataFrames into one\n",
    "        sampled_df = pd.concat([sampled_df_botnet_not_spam, sampled_df_botnet_and_spam, sampled_df_no_botnet_no_spam], ignore_index=True)\n",
    "\n",
    "        # Shuffle the row order\n",
    "        sampled_df = sampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        # Delete the three variables that have been combined to free memory\n",
    "        del sampled_df_botnet_not_spam\n",
    "        del sampled_df_botnet_and_spam\n",
    "        del sampled_df_no_botnet_no_spam\n",
    "\n",
    "        # Ensure variables are deleted and memory is more efficient\n",
    "        gc.collect()\n",
    "\n",
    "        # e. Determine output file name and save sample\n",
    "        original_folder = os.path.dirname(filepath)  # Get original folder from file path\n",
    "        folder_name = os.path.basename(original_folder)  # Get folder name like '1', '2', etc.\n",
    "        \n",
    "        # Create folder inside sampled_data with original folder name\n",
    "        folder_output_path = os.path.join(output_folder, folder_name)\n",
    "        os.makedirs(folder_output_path, exist_ok=True)\n",
    "\n",
    "        base_filename = os.path.basename(filepath)  # Get original file name\n",
    "        output_filepath = os.path.join(folder_output_path, base_filename)  # Combine with output folder\n",
    "        \n",
    "        sampled_df.to_csv(output_filepath, index=False)\n",
    "        print(f\"Success! Sample saved to '{output_filepath}'\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"WARNING: File not found at '{filepath}'. Dataset {key} will be skipped.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process file {filepath}: {e}. Dataset {key} will be skipped.\")\n",
    "\n",
    "print(\"\\n--- All processes completed ---\")\n",
    "print(f\"Successfully loaded {len(dict_of_dataframes)} datasets into memory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883e7de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset yang berhasil dimuat ke memori: ['1', '2', '5', '9', '13']\n",
      "\n",
      "Menampilkan .head() dari dataset '5' (diambil dari memori):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>Dur</th>\n",
       "      <th>Proto</th>\n",
       "      <th>SrcAddr</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Dir</th>\n",
       "      <th>DstAddr</th>\n",
       "      <th>Dport</th>\n",
       "      <th>State</th>\n",
       "      <th>sTos</th>\n",
       "      <th>dTos</th>\n",
       "      <th>TotPkts</th>\n",
       "      <th>TotBytes</th>\n",
       "      <th>SrcBytes</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:21:26</td>\n",
       "      <td>12.810612</td>\n",
       "      <td>tcp</td>\n",
       "      <td>147.32.86.44</td>\n",
       "      <td>2705</td>\n",
       "      <td>-&gt;</td>\n",
       "      <td>147.32.80.13</td>\n",
       "      <td>3128</td>\n",
       "      <td>SPA_SPA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2297</td>\n",
       "      <td>1494</td>\n",
       "      <td>flow=To-Background-CVUT-Proxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 00:33:15</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>udp</td>\n",
       "      <td>147.32.84.138</td>\n",
       "      <td>48568</td>\n",
       "      <td>&lt;-&gt;</td>\n",
       "      <td>147.32.80.9</td>\n",
       "      <td>53</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>81</td>\n",
       "      <td>flow=To-Background-UDP-CVUT-DNS-Server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 07:29:42</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>udp</td>\n",
       "      <td>147.32.84.138</td>\n",
       "      <td>36854</td>\n",
       "      <td>&lt;-&gt;</td>\n",
       "      <td>147.32.80.9</td>\n",
       "      <td>53</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>206</td>\n",
       "      <td>78</td>\n",
       "      <td>flow=To-Background-UDP-CVUT-DNS-Server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 02:45:21</td>\n",
       "      <td>32.580250</td>\n",
       "      <td>tcp</td>\n",
       "      <td>147.32.84.165</td>\n",
       "      <td>1531</td>\n",
       "      <td>-&gt;</td>\n",
       "      <td>205.188.186.137</td>\n",
       "      <td>587</td>\n",
       "      <td>FSPA_FSPA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>3963</td>\n",
       "      <td>2002</td>\n",
       "      <td>flow=From-Botnet-V46-TCP-Established-SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 07:27:06</td>\n",
       "      <td>7.832476</td>\n",
       "      <td>tcp</td>\n",
       "      <td>147.32.84.165</td>\n",
       "      <td>1528</td>\n",
       "      <td>-&gt;</td>\n",
       "      <td>205.188.186.137</td>\n",
       "      <td>587</td>\n",
       "      <td>FSPA_FSPA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59</td>\n",
       "      <td>7125</td>\n",
       "      <td>4142</td>\n",
       "      <td>flow=From-Botnet-V46-TCP-Established-SPAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             StartTime        Dur Proto        SrcAddr  Sport    Dir  \\\n",
       "0  2020-01-01 00:21:26  12.810612   tcp   147.32.86.44   2705     ->   \n",
       "1  2020-01-01 00:33:15   0.000144   udp  147.32.84.138  48568    <->   \n",
       "2  2020-01-01 07:29:42   0.000381   udp  147.32.84.138  36854    <->   \n",
       "3  2020-01-01 02:45:21  32.580250   tcp  147.32.84.165   1531     ->   \n",
       "4  2020-01-01 07:27:06   7.832476   tcp  147.32.84.165   1528     ->   \n",
       "\n",
       "           DstAddr Dport      State  sTos  dTos  TotPkts  TotBytes  SrcBytes  \\\n",
       "0     147.32.80.13  3128    SPA_SPA   0.0   0.0       10      2297      1494   \n",
       "1      147.32.80.9    53        CON   0.0   0.0        2       214        81   \n",
       "2      147.32.80.9    53        CON   0.0   0.0        2       206        78   \n",
       "3  205.188.186.137   587  FSPA_FSPA   0.0   0.0       34      3963      2002   \n",
       "4  205.188.186.137   587  FSPA_FSPA   0.0   0.0       59      7125      4142   \n",
       "\n",
       "                                       Label  \n",
       "0              flow=To-Background-CVUT-Proxy  \n",
       "1     flow=To-Background-UDP-CVUT-DNS-Server  \n",
       "2     flow=To-Background-UDP-CVUT-DNS-Server  \n",
       "3  flow=From-Botnet-V46-TCP-Established-SPAM  \n",
       "4  flow=From-Botnet-V46-TCP-Established-SPAM  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran dataset '5' di memori: (100, 15)\n"
     ]
    }
   ],
   "source": [
    "# Check which keys (datasets) are available in the dictionary\n",
    "print(f\"Datasets successfully loaded into memory: {list(dict_of_dataframes.keys())}\")\n",
    "\n",
    "# Example: Access and display the first 5 rows from dataset '5' (the COMPLETE one)\n",
    "try:\n",
    "    print(\"\\nDisplaying .head() of dataset '5' (retrieved from memory):\")\n",
    "    \n",
    "    # This is how you access the COMPLETE data\n",
    "    df_5_full = dict_of_dataframes['5']\n",
    "    \n",
    "    display(df_5_full.head())\n",
    "    print(f\"Size of dataset '5' in memory: {df_5_full.shape}\")\n",
    "    \n",
    "except KeyError:\n",
    "    print(\"Dataset '5' was not successfully loaded (possibly error or not found).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}