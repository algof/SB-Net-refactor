{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819422fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# --- Paths for CTU-13 dataset ---\n",
    "dataset_files = {\n",
    "    '1': '1/capture20110810.binetflow',\n",
    "    '2': '2/capture20110811.binetflow',\n",
    "    '5': '5/capture20110815-2.binetflow',\n",
    "    '9': '9/capture20110817.binetflow',\n",
    "    '13': '13/capture20110815-3.binetflow'\n",
    "}\n",
    "# --- End paths ---\n",
    "\n",
    "# Define the folder name to save sample results\n",
    "output_folder = 'sampled_data'\n",
    "\n",
    "# Create an empty dictionary to store all DataFrames\n",
    "# This variable will 'live' after this cell is executed\n",
    "dict_of_dataframes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5fe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai proses: Membaca data & mengambil sampel...\n",
      "Folder output 'sampled_data' telah disiapkan.\n",
      "\n",
      "--- Memproses Dataset 1 ---\n",
      "Membaca file: 1/capture20110810.binetflow...\n",
      "Dataset 1 (100 baris) telah dimuat ke memori.\n",
      "Mengambil 100 baris acak dari file 1...\n",
      "Sukses! Sampel disimpan ke 'sampled_data\\1\\capture20110810.binetflow'\n",
      "\n",
      "--- Memproses Dataset 2 ---\n",
      "Membaca file: 2/capture20110811.binetflow...\n",
      "Dataset 2 (100 baris) telah dimuat ke memori.\n",
      "Mengambil 100 baris acak dari file 2...\n",
      "Sukses! Sampel disimpan ke 'sampled_data\\2\\capture20110811.binetflow'\n",
      "\n",
      "--- Memproses Dataset 5 ---\n",
      "Membaca file: 5/capture20110815-2.binetflow...\n",
      "Dataset 5 (100 baris) telah dimuat ke memori.\n",
      "Mengambil 100 baris acak dari file 5...\n",
      "Sukses! Sampel disimpan ke 'sampled_data\\5\\capture20110815-2.binetflow'\n",
      "\n",
      "--- Memproses Dataset 9 ---\n",
      "Membaca file: 9/capture20110817.binetflow...\n",
      "Dataset 9 (100 baris) telah dimuat ke memori.\n",
      "Mengambil 100 baris acak dari file 9...\n",
      "Sukses! Sampel disimpan ke 'sampled_data\\9\\capture20110817.binetflow'\n",
      "\n",
      "--- Memproses Dataset 13 ---\n",
      "Membaca file: 13/capture20110815-3.binetflow...\n",
      "Dataset 13 (100 baris) telah dimuat ke memori.\n",
      "Mengambil 100 baris acak dari file 13...\n",
      "Sukses! Sampel disimpan ke 'sampled_data\\13\\capture20110815-3.binetflow'\n",
      "\n",
      "--- Semua proses selesai ---\n",
      "Berhasil memuat 5 dataset ke memori.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting process: Reading data & taking samples...\")\n",
    "\n",
    "# 1. Create output folder if it doesn't exist\n",
    "try:\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    print(f\"Output folder '{output_folder}' has been prepared.\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Failed to create folder '{output_folder}': {e}\")\n",
    "\n",
    "# 2. Loop, read, save to dict, take samples, and save samples\n",
    "for key, filepath in dataset_files.items():\n",
    "    try:\n",
    "        print(f\"\\n--- Processing Dataset {key} ---\")\n",
    "        print(f\"Reading file: {filepath}...\")\n",
    "        \n",
    "        # a. Read file\n",
    "        df = pd.read_csv(filepath, low_memory=False)\n",
    "        total_rows = len(df)\n",
    "        \n",
    "        # b. Save COMPLETE DataFrame to dictionary\n",
    "        # This fulfills your request to access it later\n",
    "        dict_of_dataframes[key] = df\n",
    "        print(f\"Dataset {key} ({total_rows} rows) has been loaded into memory.\")\n",
    "\n",
    "        # c. Determine sample size\n",
    "        sample_size = min(100, total_rows)\n",
    "        if sample_size < 100:\n",
    "            print(f\"Warning: File {key} only has {total_rows} rows. Taking {sample_size} rows.\")\n",
    "        else:\n",
    "            print(f\"Taking 100 random rows from file {key}...\")\n",
    "\n",
    "        # d. Take samples from the DataFrame that was just read\n",
    "        sampled_df_botnet_not_spam = df[\n",
    "            df['Label'].str.contains('botnet', case=False, na=False) &\n",
    "            ~df['Label'].str.contains('spam', case=False, na=False)\n",
    "        ].sample(n=3, random_state=42)\n",
    "\n",
    "        sampled_df_botnet_and_spam = df[\n",
    "            df['Label'].str.contains('botnet', case=False, na=False) &\n",
    "            df['Label'].str.contains('spam', case=False, na=False)\n",
    "        ].sample(n=4, random_state=42)\n",
    "\n",
    "        sampled_df_no_botnet_no_spam = df[\n",
    "            ~df['Label'].str.contains('botnet', case=False, na=False) &\n",
    "            ~df['Label'].str.contains('spam', case=False, na=False)\n",
    "        ].sample(n=4, random_state=42)\n",
    "\n",
    "        # Combine the three DataFrames into one\n",
    "        sampled_df = pd.concat([sampled_df_botnet_not_spam, sampled_df_botnet_and_spam, sampled_df_no_botnet_no_spam], ignore_index=True)\n",
    "\n",
    "        # Shuffle the row order\n",
    "        sampled_df = sampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        # Delete the three variables that have been combined to free memory\n",
    "        del sampled_df_botnet_not_spam\n",
    "        del sampled_df_botnet_and_spam\n",
    "        del sampled_df_no_botnet_no_spam\n",
    "\n",
    "        # Ensure variables are deleted and memory is more efficient\n",
    "        gc.collect()\n",
    "\n",
    "        # e. Determine output file name and save sample\n",
    "        original_folder = os.path.dirname(filepath)  # Get original folder from file path\n",
    "        folder_name = os.path.basename(original_folder)  # Get folder name like '1', '2', etc.\n",
    "        \n",
    "        # Create folder inside sampled_data with original folder name\n",
    "        folder_output_path = os.path.join(output_folder, folder_name)\n",
    "        os.makedirs(folder_output_path, exist_ok=True)\n",
    "\n",
    "        base_filename = os.path.basename(filepath)  # Get original file name\n",
    "        output_filepath = os.path.join(folder_output_path, base_filename)  # Combine with output folder\n",
    "        \n",
    "        sampled_df.to_csv(output_filepath, index=False)\n",
    "        print(f\"Success! Sample saved to '{output_filepath}'\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"WARNING: File not found at '{filepath}'. Dataset {key} will be skipped.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process file {filepath}: {e}. Dataset {key} will be skipped.\")\n",
    "\n",
    "print(\"\\n--- All processes completed ---\")\n",
    "print(f\"Successfully loaded {len(dict_of_dataframes)} datasets into memory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883e7de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset yang berhasil dimuat ke memori: ['1', '2', '5', '9', '13']\n",
      "\n",
      "Menampilkan .head() dari dataset '5' (diambil dari memori):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>Dur</th>\n",
       "      <th>Proto</th>\n",
       "      <th>SrcAddr</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Dir</th>\n",
       "      <th>DstAddr</th>\n",
       "      <th>Dport</th>\n",
       "      <th>State</th>\n",
       "      <th>sTos</th>\n",
       "      <th>dTos</th>\n",
       "      <th>TotPkts</th>\n",
       "      <th>TotBytes</th>\n",
       "      <th>SrcBytes</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011/08/15 17:07:04.499651</td>\n",
       "      <td>0.382911</td>\n",
       "      <td>tcp</td>\n",
       "      <td>147.32.84.118</td>\n",
       "      <td>3387</td>\n",
       "      <td>-&gt;</td>\n",
       "      <td>178.211.170.158</td>\n",
       "      <td>6881</td>\n",
       "      <td>SRPA_FSRPA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1081</td>\n",
       "      <td>572</td>\n",
       "      <td>flow=Background-TCP-Established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011/08/15 16:54:41.704838</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>udp</td>\n",
       "      <td>221.4.204.82</td>\n",
       "      <td>41968</td>\n",
       "      <td>&lt;-&gt;</td>\n",
       "      <td>147.32.84.229</td>\n",
       "      <td>13363</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>563</td>\n",
       "      <td>78</td>\n",
       "      <td>flow=Background-UDP-Established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011/08/15 16:44:00.127854</td>\n",
       "      <td>655.896484</td>\n",
       "      <td>udp</td>\n",
       "      <td>41.190.95.253</td>\n",
       "      <td>27025</td>\n",
       "      <td>&lt;-&gt;</td>\n",
       "      <td>147.32.84.229</td>\n",
       "      <td>13363</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1690</td>\n",
       "      <td>1416</td>\n",
       "      <td>flow=Background-UDP-Established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011/08/15 17:02:09.894977</td>\n",
       "      <td>7.832476</td>\n",
       "      <td>tcp</td>\n",
       "      <td>147.32.84.165</td>\n",
       "      <td>1528</td>\n",
       "      <td>-&gt;</td>\n",
       "      <td>205.188.186.137</td>\n",
       "      <td>587</td>\n",
       "      <td>FSPA_FSPA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59</td>\n",
       "      <td>7125</td>\n",
       "      <td>4142</td>\n",
       "      <td>flow=From-Botnet-V46-TCP-Established-SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011/08/15 17:01:37.243807</td>\n",
       "      <td>8.755043</td>\n",
       "      <td>tcp</td>\n",
       "      <td>147.32.84.165</td>\n",
       "      <td>1500</td>\n",
       "      <td>-&gt;</td>\n",
       "      <td>94.100.176.20</td>\n",
       "      <td>25</td>\n",
       "      <td>S_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>flow=From-Botnet-V46-TCP-Attempt-SPAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    StartTime         Dur Proto        SrcAddr  Sport    Dir  \\\n",
       "0  2011/08/15 17:07:04.499651    0.382911   tcp  147.32.84.118   3387     ->   \n",
       "1  2011/08/15 16:54:41.704838    0.000657   udp   221.4.204.82  41968    <->   \n",
       "2  2011/08/15 16:44:00.127854  655.896484   udp  41.190.95.253  27025    <->   \n",
       "3  2011/08/15 17:02:09.894977    7.832476   tcp  147.32.84.165   1528     ->   \n",
       "4  2011/08/15 17:01:37.243807    8.755043   tcp  147.32.84.165   1500     ->   \n",
       "\n",
       "           DstAddr  Dport       State  sTos  dTos  TotPkts  TotBytes  \\\n",
       "0  178.211.170.158   6881  SRPA_FSRPA   0.0   0.0       11      1081   \n",
       "1    147.32.84.229  13363         CON   0.0   0.0        2       563   \n",
       "2    147.32.84.229  13363         CON   0.0   0.0       12      1690   \n",
       "3  205.188.186.137    587   FSPA_FSPA   0.0   0.0       59      7125   \n",
       "4    94.100.176.20     25          S_   0.0   NaN        3       186   \n",
       "\n",
       "   SrcBytes                                      Label  \n",
       "0       572            flow=Background-TCP-Established  \n",
       "1        78            flow=Background-UDP-Established  \n",
       "2      1416            flow=Background-UDP-Established  \n",
       "3      4142  flow=From-Botnet-V46-TCP-Established-SPAM  \n",
       "4       186      flow=From-Botnet-V46-TCP-Attempt-SPAM  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran dataset '5' di memori: (100, 15)\n"
     ]
    }
   ],
   "source": [
    "# Check which keys (datasets) are available in the dictionary\n",
    "print(f\"Datasets successfully loaded into memory: {list(dict_of_dataframes.keys())}\")\n",
    "\n",
    "# Example: Access and display the first 5 rows from dataset '5' (the COMPLETE one)\n",
    "try:\n",
    "    print(\"\\nDisplaying .head() of dataset '5' (retrieved from memory):\")\n",
    "    \n",
    "    # This is how you access the COMPLETE data\n",
    "    df_5_full = dict_of_dataframes['5']\n",
    "    \n",
    "    display(df_5_full.head())\n",
    "    print(f\"Size of dataset '5' in memory: {df_5_full.shape}\")\n",
    "    \n",
    "except KeyError:\n",
    "    print(\"Dataset '5' was not successfully loaded (possibly error or not found).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}